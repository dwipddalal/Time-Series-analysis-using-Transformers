# Time Series analysis using Transformers
<a href = 'https://arxiv.org/abs/1706.03762'>‘Attention Is All You Need’ </a>  describes transformers and sequence-to-sequence architecture. It comprises of encoders and decoders that uses Multi-head attention mechannism to generate a fine representation of the input features. 

## Background
<a href='https://www.kaggle.com/competitions/hackrush22-ml-challenge/leaderboard'> Hackrush'22 </a> is an intra-college (IIT Gandhinagar) hackathon in which students of all levels of gradution(B.Tech, M.Tech, Phd) can participate. It was conducted on 26th and 27th March 2022. It's a 36hour long hackathon. We(me and my team) <a href='https://www.kaggle.com/competitions/hackrush22-ml-challenge/leaderboard'>won</a> Hackrush this year. 
This is one of the many models that we made for the Hackrush'22 competetion. We made multiple models and performed intergrated stacking on top of these bases models and that's how we were able to secure first rank in this hackathon. 

## Dataset
This is a created dataset made by Varun Jain and Prof Mayank of IITGN for Hackrush'22.

  
